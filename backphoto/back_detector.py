import cv2
import numpy as np
import time
import os
import threading
from datetime import datetime
from config import CAMERA_CONFIG, DETECTION_CONFIG

class BackDetector:
    def __init__(self):
        self.cap = None
        self.background_subtractor = None
        self.is_detecting = False
        self.photo_count = 0
        self.face_cascade = None
        self.head_detection_model = None
        self.last_face_detection_time = 0
        self.face_detection_cooldown = DETECTION_CONFIG.get('face_detection_cooldown', 3)
        self.last_photo_time = 0
        self.photo_cooldown = DETECTION_CONFIG.get('photo_cooldown', 5)
        
    def play_sound(self, sound_type="photo"):
        """æ’­æ”¾å£°éŸ³æç¤º"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å£°éŸ³
        if not DETECTION_CONFIG.get('enable_sound', True):
            return
            
        def play_beep():
            try:
                # ä½¿ç”¨ç³»ç»Ÿå£°éŸ³
                if sound_type == "photo":
                    # æ‹ç…§å£°éŸ³ - çŸ­ä¿ƒçš„"å’”åš“"å£°
                    os.system('afplay /System/Library/Sounds/Glass.aiff 2>/dev/null || echo "\\a"')
                elif sound_type == "detection":
                    # æ£€æµ‹å£°éŸ³ - è½»æŸ”æç¤ºéŸ³
                    os.system('afplay /System/Library/Sounds/Ping.aiff 2>/dev/null || echo "\\a"')
            except:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç»ˆç«¯é“ƒå£°
                print("\\a", end="", flush=True)
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ’­æ”¾å£°éŸ³ï¼Œä¸é˜»å¡ä¸»ç¨‹åº
        sound_thread = threading.Thread(target=play_beep)
        sound_thread.daemon = True
        sound_thread.start()
        
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(CAMERA_CONFIG['camera_index'])
            if not self.cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_CONFIG['resolution'][0])
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_CONFIG['resolution'][1])
            self.cap.set(cv2.CAP_PROP_FPS, CAMERA_CONFIG['fps'])
            
            # åˆå§‹åŒ–èƒŒæ™¯å‡é™¤å™¨
            self.background_subtractor = cv2.createBackgroundSubtractorMOG2(
                detectShadows=True,
                varThreshold=50
            )
            
            # åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨ï¼ˆç”¨äºæ£€æµ‹å¤´éƒ¨åŒºåŸŸï¼‰
            try:
                self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            except:
                print("è­¦å‘Šï¼šæ— æ³•åŠ è½½äººè„¸æ£€æµ‹å™¨ï¼Œå°†ä½¿ç”¨åŸºç¡€æ£€æµ‹æ–¹æ³•")
            
            return True
        except Exception as e:
            print(f"å¯åŠ¨æ‘„åƒå¤´å¤±è´¥: {e}")
            return False
    
    def detect_head_back(self, frame):
        """
        æ£€æµ‹åè„‘å‹º
        ä½¿ç”¨å¤šç§æ–¹æ³•ç»“åˆæ£€æµ‹ï¼š
        1. å¤´éƒ¨åŒºåŸŸæ£€æµ‹
        2. èƒŒæ™¯å‡é™¤
        3. è¾¹ç¼˜æ£€æµ‹
        4. è½®å»“åˆ†æ
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # æ–¹æ³•1ï¼šå°è¯•æ£€æµ‹å¤´éƒ¨åŒºåŸŸ
        head_region = self.detect_head_region(gray)
        
        # æ–¹æ³•2ï¼šèƒŒæ™¯å‡é™¤
        fg_mask = self.background_subtractor.apply(gray)
        
        # å½¢æ€å­¦æ“ä½œå»å™ª
        kernel = np.ones((5, 5), np.uint8)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
        
        # æ–¹æ³•3ï¼šè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        
        # ç»“åˆå¤šç§æ£€æµ‹ç»“æœ
        if head_region is not None:
            # å¦‚æœæœ‰å¤´éƒ¨åŒºåŸŸï¼Œä¼˜å…ˆä½¿ç”¨å¤´éƒ¨åŒºåŸŸ
            combined = head_region
        else:
            # å¦åˆ™ä½¿ç”¨èƒŒæ™¯å‡é™¤å’Œè¾¹ç¼˜æ£€æµ‹
            combined = cv2.bitwise_or(fg_mask, edges)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # åˆ†æè½®å»“
        head_detected = False
        largest_contour = None
        max_area = 0
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > max_area and area > 3000:  # é™ä½æœ€å°é¢ç§¯é˜ˆå€¼ï¼Œé€‚åˆå¤´éƒ¨
                max_area = area
                largest_contour = contour
                head_detected = True
        
        return head_detected, largest_contour, combined
    
    def detect_head_region(self, gray):
        """
        æ£€æµ‹å¤´éƒ¨åŒºåŸŸ
        ä½¿ç”¨äººè„¸æ£€æµ‹å™¨æ¥å®šä½å¤´éƒ¨åŒºåŸŸï¼Œç„¶åæ£€æµ‹åè„‘å‹º
        """
        if self.face_cascade is None:
            return None
        
        # æ£€æµ‹äººè„¸ï¼ˆæ­£é¢ï¼‰
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
        
        if len(faces) > 0:
            # å¦‚æœæ£€æµ‹åˆ°æ­£é¢äººè„¸ï¼Œè®°å½•æ—¶é—´å¹¶è¿”å›Noneï¼ˆä¸æ‹æ­£è„¸ï¼‰
            self.last_face_detection_time = time.time()
            return None
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…ï¼ˆåˆšæ£€æµ‹åˆ°æ­£è„¸ï¼‰
        current_time = time.time()
        if current_time - self.last_face_detection_time < self.face_detection_cooldown:
            return None
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ­£é¢äººè„¸ä¸”ä¸åœ¨å†·å´æœŸï¼Œå¯èƒ½æ˜¯åè„‘å‹º
        # ä½¿ç”¨æ›´å®½æ¾çš„å‚æ•°æ£€æµ‹å¯èƒ½çš„å¤´éƒ¨åŒºåŸŸ
        head_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')
        if head_cascade.empty():
            return None
        
        # æ£€æµ‹ä¾§é¢è½®å»“
        profiles = head_cascade.detectMultiScale(gray, 1.1, 4)
        
        if len(profiles) > 0:
            # åˆ›å»ºå¤´éƒ¨åŒºåŸŸæ©ç 
            mask = np.zeros(gray.shape, dtype=np.uint8)
            for (x, y, w, h) in profiles:
                # æ‰©å±•æ£€æµ‹åŒºåŸŸ
                x = max(0, x - w//4)
                y = max(0, y - h//4)
                w = min(gray.shape[1] - x, w + w//2)
                h = min(gray.shape[0] - y, h + h//2)
                cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)
            return mask
        
        return None
    
    def is_in_detection_area(self, contour, frame_shape):
        """æ£€æŸ¥è½®å»“æ˜¯å¦åœ¨æ£€æµ‹åŒºåŸŸå†…"""
        if contour is None:
            return False
        
        # è·å–è½®å»“çš„è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(contour)
        
        # æ£€æµ‹åŒºåŸŸé…ç½® (x, y, width, height)
        det_x, det_y, det_w, det_h = DETECTION_CONFIG['back_detection_area']
        
        # è½¬æ¢ä¸ºåƒç´ åæ ‡
        frame_h, frame_w = frame_shape[:2]
        det_x_px = int(det_x * frame_w)
        det_y_px = int(det_y * frame_h)
        det_w_px = int(det_w * frame_w)
        det_h_px = int(det_h * frame_h)
        
        # æ£€æŸ¥è½®å»“ä¸­å¿ƒæ˜¯å¦åœ¨æ£€æµ‹åŒºåŸŸå†…
        center_x = x + w // 2
        center_y = y + h // 2
        
        return (det_x_px <= center_x <= det_x_px + det_w_px and
                det_y_px <= center_y <= det_y_px + det_h_px)
    
    def take_photo(self, frame):
        """æ‹æ‘„ç…§ç‰‡"""
        try:
            # æ’­æ”¾æ‹ç…§å£°éŸ³æç¤º
            self.play_sound("photo")
            
            # åˆ›å»ºç…§ç‰‡ç›®å½•
            photo_dir = "photos"
            if not os.path.exists(photo_dir):
                os.makedirs(photo_dir)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{photo_dir}/photo_{timestamp}_{self.photo_count:03d}.jpg"
            
            # ä¿å­˜å¹²å‡€çš„ç…§ç‰‡ï¼ˆæ²¡æœ‰æ¡†çº¿å’Œæ–‡å­—ï¼‰
            # é‡æ–°ä»æ‘„åƒå¤´è·å–ä¸€å¸§å¹²å‡€çš„ç”»é¢
            ret, clean_frame = self.cap.read()
            if ret:
                cv2.imwrite(filename, clean_frame)
            else:
                # å¦‚æœæ— æ³•è·å–æ–°å¸§ï¼Œä½¿ç”¨å½“å‰å¸§ä½†å»æ‰æ‰€æœ‰ç»˜åˆ¶å†…å®¹
                cv2.imwrite(filename, frame)
            
            self.photo_count += 1
            
            print(f"ğŸ“¸ ç…§ç‰‡å·²ä¿å­˜: {filename}")
            return filename
            
        except Exception as e:
            print(f"æ‹ç…§å¤±è´¥: {e}")
            return None
    
    def start_detection(self, callback=None):
        """
        å¼€å§‹åèƒŒæ£€æµ‹
        callback: æ£€æµ‹åˆ°åèƒŒæ—¶çš„å›è°ƒå‡½æ•°
        """
        if not self.cap:
            if not self.start_camera():
                return False
        
        self.is_detecting = True
        last_photo_time = 0
        photo_interval = DETECTION_CONFIG['photo_delay']
        
        print("å¼€å§‹åèƒŒæ£€æµ‹...")
        print("è¯·ååœ¨æ¤…å­ä¸Šï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹å¹¶æ‹ç…§")
        print("æŒ‰ESCé”®é€€å‡ºæ£€æµ‹")
        
        while self.is_detecting:
            ret, frame = self.cap.read()
            if not ret:
                continue
            
            # æ£€æµ‹åè„‘å‹º
            head_detected, contour, mask = self.detect_head_back(frame)
            
            # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æ­£è„¸
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4) if self.face_cascade else []
            
            # ç»˜åˆ¶æ£€æµ‹åŒºåŸŸ
            frame_h, frame_w = frame.shape[:2]
            det_x, det_y, det_w, det_h = DETECTION_CONFIG['back_detection_area']
            det_x_px = int(det_x * frame_w)
            det_y_px = int(det_y * frame_h)
            det_w_px = int(det_w * frame_w)
            det_h_px = int(det_h * frame_h)
            
            # æ ¹æ®æ£€æµ‹çŠ¶æ€æ”¹å˜æ£€æµ‹åŒºåŸŸé¢œè‰²
            if len(faces) > 0:
                # æ£€æµ‹åˆ°æ­£è„¸ï¼Œæ˜¾ç¤ºçº¢è‰²è­¦å‘Š
                cv2.rectangle(frame, (det_x_px, det_y_px), 
                             (det_x_px + det_w_px, det_y_px + det_h_px), 
                             (0, 0, 255), 3)
                cv2.putText(frame, "FACE DETECTED - NO PHOTO", (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            #
            
            # å¦‚æœæ£€æµ‹åˆ°åè„‘å‹ºä¸”åœ¨æ£€æµ‹åŒºåŸŸå†…ï¼Œä¸”æ²¡æœ‰æ£€æµ‹åˆ°æ­£è„¸
            if head_detected and self.is_in_detection_area(contour, frame.shape) and len(faces) == 0:
                current_time = time.time()
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                if contour is not None:
                    x, y, w, h = cv2.boundingRect(contour)
                
                    cv2.putText(frame, "Head Back Detected!", (x, y - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                # æ£€æŸ¥æ‹ç…§é—´éš”å’Œå»é‡æœºåˆ¶
                if (current_time - last_photo_time > photo_interval and 
                    current_time - self.last_photo_time > self.photo_cooldown):
                    print("æ£€æµ‹åˆ°åè„‘å‹ºï¼Œå‡†å¤‡æ‹ç…§...")
                    time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿç¡®ä¿ç¨³å®š
                    
                    # æ‹ç…§
                    photo_path = self.take_photo(frame)
                    if photo_path and callback:
                        callback(photo_path)
                    
                    last_photo_time = current_time
                    self.last_photo_time = current_time  # è®°å½•æœ€åæ‹ç…§æ—¶é—´
                else:
                    # æ˜¾ç¤ºç­‰å¾…æç¤º
                    remaining_time = max(0, self.photo_cooldown - (current_time - self.last_photo_time))
                    cv2.putText(frame, f"Photo cooldown: {remaining_time:.1f}s", (10, 90), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            else:
                cv2.putText(frame, "Waiting for head back...", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            # æ·»åŠ é€€å‡ºæç¤º
            cv2.putText(frame, "Press ESC or Q to exit", (10, frame.shape[0] - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('åè„‘å‹ºæ£€æµ‹ - æŒ‰ESCé”®é€€å‡º', frame)
            
            # æ£€æŸ¥æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESCé”®
                print("\nğŸ›‘ ç”¨æˆ·æŒ‰ESCé”®åœæ­¢æ£€æµ‹")
                self.is_detecting = False
            elif key == ord('q') or key == ord('Q'):  # Qé”®
                print("\nğŸ›‘ ç”¨æˆ·æŒ‰Qé”®åœæ­¢æ£€æµ‹")
                self.is_detecting = False
        
        cv2.destroyAllWindows()
        return True
    
    def stop_detection(self):
        """åœæ­¢æ£€æµ‹"""
        self.is_detecting = False
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        self.stop_detection()

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    detector = BackDetector()
    
    def photo_callback(photo_path):
        print(f"ç…§ç‰‡å·²æ‹æ‘„: {photo_path}")
    
    detector.start_detection(photo_callback)
